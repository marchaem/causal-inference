{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Causalinference_Criteo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marchaem/causal-inference/blob/master/Causalinference_Criteo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWAzEQh3hTZo",
        "colab_type": "text"
      },
      "source": [
        "# <font color=Darkred>Causal inference in observational data</font>\n",
        "---\n",
        "\n",
        "\n",
        "## <font color=Darkblue>Digital advertising industry.  </font>\n",
        "\n",
        "> Diemert et al (2018). __A Large Scale Benchmark for Uplift Modeling__, _Proceedings of the AdKDD and TargetAd Workshop_, KDD. London, United Kingdom (August 20). [Data info](https://ailab.criteo.com/criteo-uplift-prediction-dataset/). [Link to the article](https://s3.us-east-2.amazonaws.com/criteo-uplift-dataset/large-scale-benchmark.pdf).\n",
        "\n",
        " In the digital advertising industry, the treatment is exposure to different ads and uplift\n",
        "modeling is used to direct marketing efforts towards users for whom\n",
        "it is the most efficient. \n",
        "\n",
        "To foster research in this topic, [Criteo](https://ailab.criteo.com/) release a publicly available collection of 25 million samples from a\n",
        "randomized control trial, scaling up previously available datasets\n",
        "by a healthy 590x factor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNDGJvAIkhyY",
        "colab_type": "text"
      },
      "source": [
        "Here we use [`causalinference`](http://causalinferenceinpython.org/index.html): a `python` package that implements various statistical and econometric methods used in the field variously known as Causal Inference, Program Evaluation, or Treatment Effect Analysis.\n",
        "<br> \n",
        "\n",
        "Also check the `causalinference` [vignette](https://github.com/laurencium/causalinference/blob/master/docs/tex/vignette.pdf). Work on [`Causalinference`](http://causalinferenceinpython.org/index.html) started in 2014 by Laurence Wong as a personal side project.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeNGLx5o22rE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install causalinference"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "48SHPNYO5YiY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQTHF16A2nST",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### <font color=Darkred>1. The dataset</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cd6NyQZZ38B6",
        "colab_type": "text"
      },
      "source": [
        "The CRITEO-UPLIFT dataset is constructed by assembling data\n",
        "resulting from several incrementality tests, a particular randomized trial procedure where a random part of the population is prevented from being targeted by advertising. \n",
        "\n",
        "The dataset consists of 25M rows, each one representing a user with 12 features, a treatment indicator and 2 binary labels (visits and conversions). \n",
        "* Positive labels mean the user visited/converted on the advertiser website during the test period (2 weeks).\n",
        "\n",
        "* It is usual that advertisers keep only a small control population as it costs them in potential revenue. \n",
        "\n",
        "* For privacy reasons the data has been sub-sampled non-uniformly so that the original incrementality level cannot be deduced from the dataset while preserving a realistic, challenging benchmark. \n",
        "\n",
        "* Feature names have been anonymized and their values randomly projected so as to keep predictive power while making it practically impossible to recover the original features or user context. \n",
        "\n",
        "The dataset is available publicly from the Criteo datasets Web page.\n",
        "\n",
        "To save time, we are going to use a reduced version of the original dataset with only 10k observations,  with a convertion ratio of around 50% in each group.\n",
        "\n",
        "__Obs: our working sub-sample is very different than the original proportions__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxh8h8VqhRXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mA2SSMeAEiC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('Criteo_uplift_raw_reduced.csv', delimiter=',')\n",
        "print('Number of rows and columns:', df.shape)\n",
        "print('Data types:', df.dtypes)\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRBxcDOsAdBe",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### <font color=Darkred>2. Descriptive analysis</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JUZe5iWBXUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Summary statitics\n",
        "df.describe().round(2).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Rs-tjZ0A9_i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To produce a table with the desc stats of the variables of interest\n",
        "df[['treatment','exposure','visit','conversion']].groupby('treatment').describe().round(2).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGKj4mGZS7g5",
        "colab_type": "text"
      },
      "source": [
        "We could also generate the same table by `visit`. We would see that conversions are perfectly mediated by attrating visitors to the website, as expected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8Y7oloyCCJu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the plot\n",
        "plt.figure(figsize=(6,6))\n",
        "\n",
        "# Plots\n",
        "sns.set(style=\"whitegrid\")\n",
        "graph1 = sns.barplot(x=\"treatment\", y=\"conversion\", data=df, \n",
        "                     capsize=.02, palette=\"Paired_r\")\n",
        "\n",
        "# Further customize\n",
        "plt.xlabel('Treatment, Yes = 1, No = 0', size = 'x-large')\n",
        "plt.ylim(0, 0.6 )\n",
        "plt.ylabel('Ratio', size = 'x-large') \n",
        "plt.title('Convertion rates by study group', \n",
        "          loc = \"left\", size = 'xx-large', pad = 40)\n",
        "plt.tight_layout();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jE3u3nOrEyD8",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "### <font color=Darkred>3. Causal inference</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2uhwtpfFDqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The outcome of interest will be - conversion -\n",
        "conversion = df.loc[:,\"conversion\"].to_numpy()\n",
        "conversion.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGzGL4G0GAhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare the treatement indicator variable\n",
        "treatment = df.loc[:, \"treatment\"].to_numpy()\n",
        "treatment.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1h2PtJ6FnY_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declare the set of covariates\n",
        "X = df.loc[:, [\"f0\",\"f1\",\"f2\",\"f3\",\"f4\",\"f5\",\"f6\",\"f7\",\"f8\",\"f9\",\"f10\",\"f11\"]].to_numpy()\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cw1EhYxVEsmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the model\n",
        "from causalinference import CausalModel\n",
        "causal = CausalModel(conversion, treatment, X)\n",
        "\n",
        "print(causal.summary_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXoWhPsEHdCk",
        "colab_type": "text"
      },
      "source": [
        "This table is just a descriptive summary of the dataset. Similar to what we generated earlier using the `describe`, `bygroup` from `pandas`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcZM6--jHZ0c",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### <font color=Darkred>3.1 Ordinary Least Squares (OLS) estimation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae9IFTpqHU9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "causal.est_via_ols()\n",
        "print(causal.estimates)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EzfgrTrIrwK",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "#### <font color=Darkred>3.2 Propensity scoring estimation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_efvR9VHLBpY",
        "colab_type": "text"
      },
      "source": [
        "To estimate the propensity scores, we run a logistic regression of __treatment__ on the covariates (and tranformations of them) This feature engineering and selection is done automatically by the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IuqkQInIqU5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "causal.est_propensity_s()\n",
        "print(causal.propensity)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3ju82zTLvlM",
        "colab_type": "text"
      },
      "source": [
        "To improve the balance between the characteristics of the two groups, we can __trim__ the data by excluding extreme values of the propensity score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INm_2ZkXLt58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To trim the data and exclude extreme propensity scores\n",
        "causal.trim_s()\n",
        "causal.cutoff"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DpWRcWsMHFg",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "\n",
        "The optimal cutoff ($\\alpha$) suggested by the package is shown above. This means it has dropped observations outside the interval [$\\alpha$, 1 - $\\alpha$]. Let's show the summary statistics table again to see what happened."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wunUSvnM2Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(causal.summary_stats)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_pjCy6KN6gY",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the propensity scores, we can __stratify__ the sample into blocks that have units that are more similar in terms of their covariates.\n",
        "\n",
        "This will make the treatment and the control groups more comparable within each propensity bin, therefore creating a more convincing counterfactual. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NpGtAF_NV8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The default is blocks = 6\n",
        "causal.stratify_s()\n",
        "print(causal.strata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrjv5wktP2S0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "causal.est_via_ols()\n",
        "causal.est_via_blocking()\n",
        "causal.est_via_matching(bias_adj=True) ## One-to-one nearest neighbour matching is default\n",
        "\n",
        "print(causal.estimates)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkGwF2QuU020",
        "colab_type": "text"
      },
      "source": [
        "As we control for the covariate imbalance, the treatment effect converges to zero. \n",
        "\n",
        "* This is not the result obtained in the paper using the 25 million observations. But it is good to highlight how sensitive the results are to sampling bias.\n",
        "* Also, might be due to the fact that I forced the sampling of the 10k observation to have 50% of the examples experiencing a conversion."
      ]
    }
  ]
}